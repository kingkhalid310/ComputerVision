{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and validating pipeline for the QSM 3D segmentation project \n",
        "# Course: cs512\n",
        "# instructor: Gady Agam\n",
        "# Group 1: \n",
        "# Rasheed Abid, rabid@hawk.iit.edu\n",
        "# Khalid Saifullah, ksaifullah@hawk.iit.edu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# installations if required\n",
        "!pip install patchify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AlJ_fpd8scE"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from patchify import patchify, unpatchify\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Activation, MaxPool2D, Concatenate, add\n",
        "\n",
        "print(\"Tensorflow version = \" + tf.__version__)\n",
        "print(\"Keras version = \" + keras.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6L3eZwk86Yr",
        "outputId": "7a68505a-8b13-4678-a973-5d12a6c38f07"
      },
      "outputs": [],
      "source": [
        "# incase of running on google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# changing variables # this is the only section that needs to be changed\n",
        "\n",
        "# maindir = \"/content/drive/MyDrive/Colab Notebooks/CS512/project\"\n",
        "maindir = \"/Users/badhon/Desktop/cs512/cs512_project_gdrive_runs\"\n",
        "subject_num = 80 # available ones are 32, 64, 80, 100\n",
        "subject_num_testing = 20 # available ones are 9, 20\n",
        "label_name = \"amygdala\"\n",
        "epochs = 50\n",
        "dim = 128\n",
        "n_classes = 1\n",
        "model_to_run = \"unet\" # available ones are \"res_unet\" and \"unet\"\n",
        "\n",
        "# architecture parameters\n",
        "patch_size = 64 # testing with 64x64x64 patches\n",
        "channels=1\n",
        "\n",
        "LR = 0.0001 # Learning rate\n",
        "optim = keras.optimizers.Adam(LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# directories \n",
        "\n",
        "os.chdir( maindir )\n",
        "source_dir = os.path.join(maindir, \"data_dir\")\n",
        "results_dir = os.path.join(maindir, \"results_dir\")\n",
        "files_dir = os.path.join(maindir, \"files\")\n",
        "scripts_dir = os.path.join(maindir, \"scripts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "je1WviY89M2I",
        "outputId": "c0b10708-364d-4ef3-ccbd-bc0e09d3d98e"
      },
      "outputs": [],
      "source": [
        "# file names\n",
        "saved_model_name = label_name + \"_mask_dim\" + str(dim) + \"_sub\" + str(subject_num) + \"_e\" + str(epochs) + \"_checking_new_model_.h5\"\n",
        "saved_model_name = os.path.join(results_dir, \"saved_models\", saved_model_name)\n",
        "\n",
        "subject_filename = \"filename_sub\" + str(subject_num) + \".txt\"\n",
        "filename = os.path.join(files_dir, subject_filename)\n",
        "test_filename = os.path.join(files_dir, \"filename_testing\" + str(subject_num_testing) + \".txt\")\n",
        "\n",
        "\n",
        "print(saved_model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Suffix for the files is = 4\n"
          ]
        }
      ],
      "source": [
        "# suffix selection for images\n",
        "if dim == 256:\n",
        "    Suffix = 2\n",
        "elif dim ==  128:\n",
        "    Suffix = 4\n",
        "else:\n",
        "    Suffix = 8\n",
        "\n",
        "print( \"Suffix for the files is = %d\" %Suffix )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a unet with skip connections for our model\n",
        "\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv3D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)   #Not in the original network. \n",
        "    x = Activation(\"relu\")(x)\n",
        "    return x\n",
        "\n",
        "#Encoder block:\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPooling3D((2, 2, 2))(x)\n",
        "    return x, p   \n",
        "\n",
        "#Decoder block\n",
        "#skip features gets input from encoder for concatenation\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv3DTranspose(num_filters, (2, 2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "#Build Unet using the blocks\n",
        "def build_unet(input_shape, n_classes):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 32)\n",
        "    s2, p2 = encoder_block(p1, 64)\n",
        "    s3, p3 = encoder_block(p2, 128)\n",
        "    s4, p4 = encoder_block(p3, 256)\n",
        "\n",
        "    b1 = conv_block(p4, 512) # Bridge\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "    \n",
        "    f1 = conv_block(d4, 32)\n",
        "    \n",
        "    if n_classes == 1:  # For singular mask checking\n",
        "      activation = 'sigmoid'\n",
        "    else: # for multilevel label checking\n",
        "      activation = 'softmax'\n",
        "\n",
        "    outputs = Conv3D(n_classes, 1, padding=\"same\", activation=activation)(f1)  #Change the activation based on n_classes\n",
        "    print(activation)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"UNet\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def res_block(x, nb_filters, strides):\n",
        "    res_path = BatchNormalization()(x)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    res_path = Conv3D(filters=nb_filters[0], kernel_size=(3, 3, 3), padding=\"same\", strides=strides[0])(res_path)\n",
        "    res_path = BatchNormalization()(res_path)\n",
        "    res_path = Activation(activation='relu')(res_path)\n",
        "    res_path = Conv3D(filters=nb_filters[1], kernel_size=(3, 3, 3), padding=\"same\", strides=strides[1])(res_path)\n",
        "\n",
        "    shortcut = Conv3D(nb_filters[1], kernel_size=(1, 1, 1), strides=strides[0])(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    res_path = add([shortcut, res_path])\n",
        "    return res_path\n",
        "\n",
        "\n",
        "def encoder(x):\n",
        "    to_decoder = []\n",
        "\n",
        "    main_path = Conv3D(filters=64, kernel_size=(3, 3, 3), padding=\"same\", strides=(1, 1, 1))(x)\n",
        "    main_path = BatchNormalization()(main_path)\n",
        "    main_path = Activation(activation='relu')(main_path)\n",
        "\n",
        "    main_path = Conv3D(filters=64, kernel_size=(3, 3, 3), padding=\"same\", strides=(1, 1, 1))(main_path)\n",
        "\n",
        "    shortcut = Conv3D(filters=64, kernel_size=(1, 1, 1), strides=(1, 1, 1))(x)\n",
        "    shortcut = BatchNormalization()(shortcut)\n",
        "\n",
        "    main_path = add([shortcut, main_path])\n",
        "    \n",
        "    # first branching to decoder\n",
        "    to_decoder.append(main_path)\n",
        "\n",
        "    main_path = res_block(main_path, [128, 128], [(2, 2, 2), (1, 1, 1)])\n",
        "    to_decoder.append(main_path)\n",
        "\n",
        "    main_path = res_block(main_path, [256, 256], [(2, 2, 2), (1, 1, 1)])\n",
        "    to_decoder.append(main_path)\n",
        "\n",
        "    return to_decoder\n",
        "\n",
        "\n",
        "def decoder(x, from_encoder):\n",
        "    main_path = UpSampling3D(size=(2, 2, 2))(x)\n",
        "    main_path = concatenate([main_path, from_encoder[2]])\n",
        "    main_path = res_block(main_path, [256, 256], [(1, 1, 1), (1, 1, 1)])\n",
        "\n",
        "    main_path = UpSampling3D(size=(2, 2, 2))(main_path)\n",
        "    main_path = concatenate([main_path, from_encoder[1]])\n",
        "    main_path = res_block(main_path, [128, 128], [(1, 1, 1), (1, 1, 1)])\n",
        "\n",
        "    main_path = UpSampling3D(size=(2, 2, 2))(main_path)\n",
        "    main_path = concatenate([main_path, from_encoder[0]])\n",
        "    main_path = res_block(main_path, [64, 64], [(1, 1, 1), (1, 1, 1)])\n",
        "\n",
        "    return main_path\n",
        "\n",
        "\n",
        "def build_res_unet(input_shape, n_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    to_decoder = encoder(inputs)\n",
        "\n",
        "    path = res_block(to_decoder[2], [512, 512], [(2, 2, 2), (1, 1, 1)])\n",
        "\n",
        "    path = decoder(path, from_encoder=to_decoder)\n",
        "\n",
        "    path = Conv3D(filters=n_classes, kernel_size=(1, 1, 1), activation='sigmoid')(path)\n",
        "\n",
        "    return Model(inputs, path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make sure the GPU is available. \n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# function to normalize the nifti data once converted to numpy array, and then multiply by the mask\n",
        "# of the brain\n",
        "\n",
        "def norm_nifti(img, brain_mask_data=None):\n",
        "    # We are normalizing the data to be between 0 and 1\n",
        "    min_value = np.min(img)\n",
        "    max_value = np.max(img)\n",
        "    normalized_data = (img - min_value) / (max_value - min_value)\n",
        "    \n",
        "    # We are multiplying the normalized data by the brain mask\n",
        "    if brain_mask_data is not None:\n",
        "        normalized_data = normalized_data * brain_mask_data\n",
        "    \n",
        "    return normalized_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filename = filename\n",
        "\n",
        "# initialize lists to store the patches\n",
        "all_img_patches = []\n",
        "all_mask_patches = []\n",
        "val=0\n",
        "\n",
        "with open(filename) as f:\n",
        "    for line in f:\n",
        "        print(\"Currently processing subject number: %d\" %val)\n",
        "        val=val+1\n",
        "        subject_id = line.strip()\n",
        "\n",
        "\n",
        "        # read filenames\n",
        "        imagename = os.path.join(source_dir, subject_id, \"QSM_dim\" + str(dim) + \".nii.gz\")\n",
        "        maskname = os.path.join(source_dir, subject_id, label_name + \"_dim\" + str(dim) + \".nii.gz\")\n",
        "        brain_mask_name = os.path.join(source_dir, subject_id, \"QSM_brain_mask_dim\" + str(dim) + \".nii.gz\")\n",
        "\n",
        "\n",
        "        if not (os.path.exists(imagename) and os.path.exists(maskname) and os.path.exists(brain_mask_name) ):\n",
        "            print(\"Some files are missing\")\n",
        "        \n",
        "        # Read images\n",
        "        img = nib.load(imagename)\n",
        "        img_data = img.get_fdata().astype(np.float32)\n",
        "        \n",
        "        # Read mask\n",
        "        mask = nib.load(maskname)\n",
        "        mask_data = mask.get_fdata().astype(np.float32)\n",
        "\n",
        "        # Read brain mask\n",
        "        brain_mask = nib.load(brain_mask_name)\n",
        "        brain_mask_data = brain_mask.get_fdata().astype(np.float32)\n",
        "        \n",
        "\n",
        "        #Normalise using the function we wrote\n",
        "        # img_data = norm_nifti(img_data) # if you don't want to use the brain mask\n",
        "        img_data = norm_nifti(img_data, brain_mask_data) # if you want to use the brain mask\n",
        "        \n",
        "\n",
        "        #Patchify the image and mask\n",
        "        patches_img = patchify(img_data, (patch_size, patch_size, patch_size), step=64)  # Step=256 for 256 patches means no overlap\n",
        "        patches_mask = patchify(mask_data, (patch_size, patch_size, patch_size), step=64)  # Step=256 for 256 patches means no overlap\n",
        "        \n",
        "\n",
        "        for i in range(patches_img.shape[0]):\n",
        "            for j in range(patches_img.shape[1]):\n",
        "                for k in range(patches_img.shape[2]):\n",
        "                    \n",
        "                    #image\n",
        "                    single_patch_img = patches_img[i,j,k,:,:,:]\n",
        "                    all_img_patches.append(single_patch_img)\n",
        "                    \n",
        "                    #mask\n",
        "                    single_patch_mask = patches_mask[i,j,k,:,:,:]\n",
        "                    all_mask_patches.append(single_patch_mask)\n",
        "        # image stacking \n",
        "        all_patched_stacked_images = np.array(all_img_patches)\n",
        "        # mask stacking\n",
        "        all_patched_stacked_masks = np.array(all_mask_patches)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the shapes\n",
        "print(all_patched_stacked_images.shape)\n",
        "print(all_patched_stacked_masks.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_images = all_patched_stacked_images\n",
        "training_masks = all_patched_stacked_masks\n",
        "\n",
        "# train_test_split at 30%\n",
        "# Here X_test and y_test are actually validation data\n",
        "X_train, X_test, y_train, y_test = train_test_split(training_images, training_masks, test_size=0.3, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Loss functions and dice metrics\n",
        "# both for binary and multiclass segmentation\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    smoothing_factor = 1 # to avoid division by zero\n",
        "    \n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f)\n",
        "    dice = (2. * intersection + smoothing_factor) / (union + smoothing_factor)\n",
        "    return dice\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def dice_coef_multilabel(y_true, y_pred, numLabels=1):\n",
        "    dice=0\n",
        "    for index in range(numLabels):\n",
        "        dice -= dice_coef(y_true[...,index], y_pred[...,index])\n",
        "    return dice/numLabels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if model_to_run == \"unet\":\n",
        "    model = build_unet((patch_size, patch_size, patch_size, channels), n_classes=n_classes)\n",
        "elif model_to_run == \"res_unet\":\n",
        "    model = build_res_unet((patch_size, patch_size, patch_size, channels), n_classes=n_classes)\n",
        "else:\n",
        "    print(\"Please choose a valid model. Available models are: unet, res_unet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n",
        "print( model.summary() )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check all the shapes\n",
        "print(model.input_shape)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print( X_train.max() ) # 1.0 after normalization\n",
        "print( X_train.min() ) # 0.0 after normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fit the model\n",
        "print(\" The model is being trained now for %d epochs\" %epochs)\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    batch_size=4, \n",
        "                    epochs=epochs, \n",
        "                    verbose=1, \n",
        "                    validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the model\n",
        "model.save( saved_model_name )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the traning and validation loss\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "acc = history.history['dice_coefficient']\n",
        "val_acc = history.history['val_dice_coefficient']\n",
        "\n",
        "plt.plot(epochs, acc, 'y', label='Training Dice')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation Dice')\n",
        "plt.title('Training and validation Dice')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Dice')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if asked, reload the model\n",
        "# model = keras.models.load_model(saved_model_name)\n",
        "\n",
        "# if the previous one is not working, try this one\n",
        "# model = keras.models.load_model(saved_model_name, custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# predict on the validation set to visualize the results\n",
        "y_pred = model.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check the shapes\n",
        "print(y_pred.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize the predicted and ground truth masks\n",
        "num = 10 # image number\n",
        "sl = 62 # slice number\n",
        "\n",
        "fig, ax = plt.subplots(nrows=1, ncols=3)\n",
        "im1 = ax[0].imshow(X_test[num,:, sl, :])\n",
        "ax[0].set_title('Original Image patch') \n",
        "ax[0].axis(\"off\")\n",
        "fig.colorbar(im1, ax = ax[0])\n",
        "\n",
        "x = y_pred[num, :, :, :]\n",
        "im2 = ax[1].imshow(x[:, sl, :, 0])\n",
        "ax[1].set_title('Predicted Mask patch')\n",
        "ax[1].axis(\"off\")\n",
        "fig.colorbar(im2, ax = ax[1])\n",
        "\n",
        "\n",
        "im3 = ax[2].imshow(y_test[num, :, sl, :])\n",
        "ax[2].set_title('Ground Truth Mask patch')\n",
        "ax[2].axis(\"off\")\n",
        "fig.colorbar(im3, ax = ax[2])\n",
        "\n",
        "# Show the subplot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_pred.dtype)\n",
        "y_pred = (y_pred>0.5).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# find dice for the whole test dataset\n",
        "print(\"Dice results for the whole validation dataset is: \" + str(dice_coef(y_test, y_pred)) )\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
