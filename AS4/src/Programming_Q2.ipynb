{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "iOLL0U8sUUPv"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import cv2\n",
        "import struct\n",
        "import argparse\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import add, concatenate\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "# import darknet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtWS0V_4V3C6",
        "outputId": "b378bbe8-05db-4d40-a25c-f8fdf60aed91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Tm5xifcyUUPy"
      },
      "outputs": [],
      "source": [
        "class WeightRead:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            binary = w_f.read()\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance            \n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                    print(\"No conv\")\n",
        "        \n",
        "    def load_weights_h5(self, model):\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        self.offset = 0\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BoundingBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "        return self.score\n",
        "\n",
        "def convolutional_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding\n",
        "        x = Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "    return add([skip_connection, x]) if skip else x\n",
        "\n",
        "def interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3          \n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union\n",
        "\n",
        "def yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = convolutional_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = convolutional_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = convolutional_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = convolutional_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = convolutional_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = convolutional_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = convolutional_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = convolutional_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = convolutional_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = convolutional_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = convolutional_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = convolutional_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = convolutional_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = convolutional_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = convolutional_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = convolutional_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
        "    return model\n",
        "\n",
        "def preprocess_input(image, net_height, net_width):\n",
        "    new_h, new_w, _ = image.shape\n",
        "    # new size of the image\n",
        "    if (float(net_width)/new_w) < (float(net_height)/new_h):\n",
        "        new_h = (new_h * net_width)/new_w\n",
        "        new_w = net_width\n",
        "    else:\n",
        "        new_w = (new_w * net_height)/new_h\n",
        "        new_h = net_height\n",
        "\n",
        "    # resize the image\n",
        "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
        "\n",
        "    # embed the image\n",
        "    new_image = np.ones((net_height, net_width, 3)) * 0.5\n",
        "    new_image[int((net_height-new_h)//2):int((net_height+new_h)//2), int((net_width-new_w)//2):int((net_width+new_w)//2), :] = resized\n",
        "    new_image = np.expand_dims(new_image, 0)\n",
        "    return new_image\n",
        "\n",
        "def correct_yolo_boxes(boxes, image_height, image_width, net_height, net_width):\n",
        "    if (float(net_width)/image_width) < (float(net_height)/image_height):\n",
        "        new_w = net_width\n",
        "        new_h = (image_height*net_width)/image_width\n",
        "    else:\n",
        "        new_h = net_width\n",
        "        new_w = (image_width*net_height)/image_height\n",
        "        \n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_width - new_w)/2./net_width, float(new_w)/net_width\n",
        "        y_offset, y_scale = (net_height - new_h)/2./net_height, float(new_h)/net_height\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_width)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_width)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_height)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_height)\n",
        "\n",
        "def decode_netoutput(netout, anchors, object_thresh, nms_thresh, net_height, net_width):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "    netout[..., :2]  = sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > object_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        \n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            if(objectness.all() <= object_thresh): \n",
        "              continue\n",
        "            \n",
        "            # first 4 elements: x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_width # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_height # unit: image height  \n",
        "            \n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            box = BoundingBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            boxes.append(box)\n",
        "    return boxes\n",
        "  \n",
        "def nonmaxsuppress(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "        \n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0\n",
        "                    \n",
        "def drawing_boxes(image, boxes, labels, object_thresh):\n",
        "    for box in boxes:\n",
        "        label_str = ''\n",
        "        label = -1\n",
        "        \n",
        "        for i in range(len(labels)):\n",
        "            if box.classes[i] > object_thresh:\n",
        "                label_str += labels[i]\n",
        "                label = i\n",
        "                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n",
        "                \n",
        "        if label >= 0:\n",
        "            cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n",
        "            cv2.putText(image, \n",
        "                        label_str + ' ' + str(box.get_score()), \n",
        "                        (box.xmin, box.ymin - 13), \n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
        "                        1e-3 * image.shape[0], \n",
        "                        (0,255,0), 2)\n",
        "        \n",
        "    return image"
      ],
      "metadata": {
        "id": "u0Uf1HgrxxWY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w9omK1eUUP1",
        "outputId": "d32618a6-0ae0-495b-8ba0-58dabdfe71ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n",
            "No conv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f67b89a5d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "person: 96.92206978797913%\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "weights_path = '/content/drive/MyDrive/Colab Notebooks/CS512_AS/AS4/yolov3.weights'\n",
        "image_path   = '/content/drive/MyDrive/Colab Notebooks/CS512_AS/AS4/oxford-iiit-pet/images/Abyssinian_2.jpg' #Abyssinian_22.jpg, american_bulldog_5.jpg\n",
        "\n",
        "# set some parameters\n",
        "net_height, net_width = 416, 416\n",
        "obj_thresh, nms_thresh = 0.5, 0.45\n",
        "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
        "labels = [\"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\", \\\n",
        "            \"person\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
        "            \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
        "            \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
        "            \"bird\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\"]\n",
        "\n",
        "# yolov3 model\n",
        "yolov3 = yolov3_model()\n",
        "# loading the weights trained on COCO into our model\n",
        "weight_reader = WeightRead(weights_path)\n",
        "weight_reader.load_weights(yolov3)\n",
        "# Preprocessing Step\n",
        "image = cv2.imread(image_path)\n",
        "image_height, image_width, _ = image.shape\n",
        "new_image = preprocess_input(image, net_height, net_width)\n",
        "\n",
        "# Image Prediction\n",
        "yolo_ = yolov3.predict(new_image)\n",
        "boxes = []\n",
        "for i in range(len(yolo_)):\n",
        "    boxes += decode_netoutput(yolo_[i][0], anchors[i], obj_thresh, nms_thresh, net_height, net_width)\n",
        "# Correcting the sizes of the bounding boxes\n",
        "correct_yolo_boxes(boxes, image_height, image_width, net_height, net_width)\n",
        "# Non-maximum suppression of boxes\n",
        "nonmaxsuppress(boxes, nms_thresh)     \n",
        "# Drawing bounding boxes on the image\n",
        "drawing_boxes(image, boxes, labels, obj_thresh) \n",
        "\n",
        "# Saving the predicted image\n",
        "cv2.imwrite(image_path[:-4] + '_detected' + image_path[-4:], (image).astype('uint8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "umtBCxnLUUP2"
      },
      "outputs": [],
      "source": [
        "#Saving model\n",
        "yolov3.save_weights('/content/drive/MyDrive/Colab Notebooks/CS512_AS/AS4/yolov_tt3.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JIblxWgaqx3E"
      },
      "execution_count": 36,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}